---
title: AGI will be here sooner than you think
---

Predictions about progress are trecherous, but AI predictions are all the rage, so let's get this out of the way.

AI experts and people who enjoy predicting things say that there's a 10% that we will achieve transformative AI by 2025 ([see: literature review on EpochAI](https://epochai.org/blog/literature-review-of-transformative-artificial-intelligence-timelines)).

| 10%  | Median | 90%  |
|------|--------|------|
| 2025 | 2045   | 2107 |

That there's even a 10% chance of transformative AI in the next couple of years is absolutely mind-blowing. And yet those numbers seem reasonable.

I'd go even further: it's possible that systems like [AutoGPT] and [Reflexion] are already AGI systems. Because they can write to memory, and those memories are automatically incorporated into later prompts, they should be able to learn basically anything. Sure they have limitations, but those might be solved with the right prompt chains.

So here's my bold prediction: *one day when we have an unambiguously general AI, we will look back at AutoGPT and recognise that it has all the necessary components to also be called AGI*. I give this a 1% chance of being true â€” which, like the values above, is also astonishingly high.

[AutoGPT]: https://github.com/Significant-Gravitas/Auto-GPT#readme
[Reflexion]: https://arxiv.org/abs/2303.11366
